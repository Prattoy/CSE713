{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess"
      ],
      "metadata": {
        "id": "CMYQSDKFklge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dF-7DkRDjGc8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch #touhid\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "class SignatureDataset(Dataset):\n",
        "    def __init__(self, data_folder, transform=None):\n",
        "        self.data_folder = data_folder\n",
        "        self.image_list = os.listdir(data_folder)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = os.path.join(self.data_folder, self.image_list[idx])\n",
        "\n",
        "        if image_name.endswith(\".png\"):\n",
        "            image = Image.open(image_name)\n",
        "\n",
        "            # Convert the grayscale image to 1-channel grayscale\n",
        "            image = image.convert(\"L\")\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image\n",
        "\n",
        "\n",
        "def preprocess_data(data_folder, image_size=(128, 128), batch_size=32, test=False, device=None):\n",
        "    data_transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),  # resizes images\n",
        "        transforms.ToTensor(),  # converts to tensor\n",
        "        # transforms.Normalize(mean=[0.5], std=[0.5]),  # normalization\n",
        "    ])\n",
        "\n",
        "    signature_dataset = SignatureDataset(data_folder, transform=data_transform)\n",
        "    # Filter out None elements from the signature_dataset\n",
        "    signature_dataset = [signatures.to(device) for signatures in signature_dataset if signatures is not None]\n",
        "\n",
        "    if test:\n",
        "        # batch_size = len(signature_dataset)\n",
        "        signature_dataloader = signature_dataset\n",
        "    else:\n",
        "        signature_dataloader = DataLoader(signature_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return signature_dataloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triplet Loss"
      ],
      "metadata": {
        "id": "PxZz2fq-k2uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor_output, positive_output, negative_output):\n",
        "        distance_positive = torch.norm(anchor_output - positive_output, p=2, dim=1)\n",
        "        distance_negative = torch.norm(anchor_output - negative_output, p=2, dim=1)\n",
        "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
        "        return torch.mean(losses)\n"
      ],
      "metadata": {
        "id": "r7NZzPPUkrM7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siamese Net"
      ],
      "metadata": {
        "id": "aMa9iQouk9AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_dim, batch_size, num_heads, num_layers, dropout=0.1):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Define the CNN architecture\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        # Define the architecture of the Siamese network using Transformer\n",
        "        self.transformer_encoder = TransformerEncoder(\n",
        "            TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Calculate the number of features after Transformer layers\n",
        "        self.transformer_features = embedding_dim  # This can be adjusted based on your requirements\n",
        "\n",
        "        # Fully connected layer for producing the final embeddings\n",
        "        self.fc1 = nn.Linear(self.transformer_features, embedding_dim)\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # x = x.view(self.batch_size, 64, 256)\n",
        "        # x = x.transpose(0, 1)  # Transpose dimensions to match Transformer input format\n",
        "        # x = self.transformer_encoder(x)\n",
        "        # x = x.transpose(0, 1)  # Transpose dimensions back to batch-first\n",
        "        # x = x.mean(dim=1)  # Average over sequence length to get a fixed-size representation\n",
        "        # x = F.relu(self.fc1(x))\n",
        "\n",
        "        x = self.cnn(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.flatten(2).transpose(1, 2)  # Flatten the image features and transpose for Transformer\n",
        "        # print(x.shape)\n",
        "        # x = x.permute(0, 2, 1)\n",
        "        # print(x.shape)\n",
        "        x = self.transformer_encoder(x.to(x.device))\n",
        "        # x = self.transformer_encoder(x)\n",
        "        x = x.mean(dim=1)  # Average over sequence length to get a fixed-size representation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        anchor_output = self.forward_once(anchor)\n",
        "        positive_output = self.forward_once(positive)\n",
        "        negative_output = self.forward_once(negative)\n",
        "        return anchor_output, positive_output, negative_output\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"SiameseNetwork(embedding_dim={self.embedding_dim}, num_params={self.count_parameters()})\"\n"
      ],
      "metadata": {
        "id": "9RmC5U8KlD6S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test"
      ],
      "metadata": {
        "id": "olgkDUWNlLeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "# from triplet_loss import TripletLoss\n",
        "import time\n",
        "import torch.nn.functional as f\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "\n",
        "def train_siamese_network(siamese_net, anchor_dataloader, positive_dataloader, negative_dataloader, num_epochs=10):\n",
        "    # Initialize the Siamese network and TripletLoss\n",
        "    criterion = TripletLoss(margin=0.5)\n",
        "    optimizer = torch.optim.Adam(siamese_net.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        siamese_net.train()  # Set the model to training mode\n",
        "        for batch_idx, (anchors, positives, negatives) in enumerate(\n",
        "                zip(anchor_dataloader, positive_dataloader, negative_dataloader)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # print(anchors.shape)\n",
        "            # Reshape the tensors to [batch_size, num_channels * height * width]\n",
        "            # anchors = anchors.view(anchors.size(0), -1)  # The -1 automatically calculates the necessary size\n",
        "            # positives = positives.view(positives.size(0), -1)\n",
        "            # negatives = negatives.view(negatives.size(0), -1)\n",
        "\n",
        "            # Assuming anchors, positives, and negatives are your input tensors\n",
        "            # print(\"Anchors shape:\", anchors.size())\n",
        "            # print(\"Positives shape:\", positives.size())\n",
        "            # print(\"Negatives shape:\", negatives.size())\n",
        "\n",
        "            anchors = anchors.to(device)\n",
        "            positives = positives.to(device)\n",
        "            negatives = negatives.to(device)\n",
        "\n",
        "            # Forward pass through the Siamese Network\n",
        "            anchor_output, positive_output, negative_output = siamese_net(anchors, positives, negatives)\n",
        "\n",
        "            # Compute the triplet loss\n",
        "            loss = criterion(anchor_output, positive_output, negative_output)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            # print(loss.item())\n",
        "\n",
        "        # print(len(anchor_dataloader))\n",
        "        epoch_loss = running_loss / len(anchor_dataloader)  # Calculate the average loss for the epoch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Total training time: {total_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "def test_siamese_network(siamese_net, test_dataloader):\n",
        "    siamese_net.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        correctly_predicted = 0\n",
        "        incorrectly_predicted = 0\n",
        "        all_true_labels = []\n",
        "        all_predicted_labels = []\n",
        "\n",
        "        for anchors, positives, negatives in test_dataloader:\n",
        "\n",
        "            anchors = anchors.unsqueeze(0)  # Add batch dimension\n",
        "            positives = positives.unsqueeze(0)  # Add batch dimension\n",
        "            negatives = negatives.unsqueeze(0)  # Add batch dimension\n",
        "            # print(anchors.shape)\n",
        "\n",
        "            anchors = anchors.to(device)\n",
        "            positives = positives.to(device)\n",
        "            negatives = negatives.to(device)\n",
        "            # anchor_signature = anchor_signature.view(1, -1)  # Reshape the anchor signature\n",
        "            # test_signature = test_signature.view(1, -1)  # Reshape the test signature\n",
        "\n",
        "            # Generate random number for positive and negative\n",
        "            random_number = random.randint(0, 1)\n",
        "\n",
        "            if random_number == 0:\n",
        "                anchor_output = siamese_net.forward_once(anchors)\n",
        "                test_output = siamese_net.forward_once(negatives)\n",
        "            else:\n",
        "                anchor_output = siamese_net.forward_once(anchors)\n",
        "                test_output = siamese_net.forward_once(positives)\n",
        "\n",
        "            # Calculate the distance between anchor and test signatures\n",
        "            distance = f.pairwise_distance(anchor_output, test_output)\n",
        "\n",
        "            # If the distance is below a certain threshold, consider the test signature as genuine (positive)\n",
        "            # Otherwise, consider it as forged (negative)\n",
        "            threshold = 0.5\n",
        "            predicted_label = 1 if distance < threshold else 0\n",
        "\n",
        "            all_true_labels.append(random_number)\n",
        "            all_predicted_labels.append(predicted_label)\n",
        "\n",
        "            # print(\"Distance: {:.4f}\".format(distance.item()))\n",
        "            # print(f\"Predicted Label: {predicted_label}\")\n",
        "            # print(f\"Actual Label: {random_number}\")\n",
        "\n",
        "            if predicted_label == random_number:\n",
        "                correctly_predicted += 1\n",
        "            else:\n",
        "                incorrectly_predicted += 1\n",
        "\n",
        "\n",
        "        print(f\"Total Correctly Predicted: {correctly_predicted}\")\n",
        "        print(f\"Total Incorrectly Predicted: {incorrectly_predicted}\")\n",
        "\n",
        "        # Calculate precision, recall, f1-score, and accuracy\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_predicted_labels,\n",
        "                                                                   average='binary')\n",
        "        accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n",
        "\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DbX9otfZlODN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gma4wssmpwt",
        "outputId": "f1be2a38-1cb8-4681-a662-d5020dc041aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "VdmeUsXEludm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Selected Device: {device}')\n",
        "    train_anchor_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/train/anchor\"\n",
        "    train_positive_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/train/positive\"\n",
        "    train_negative_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/train/negative\"\n",
        "\n",
        "    # validate_anchor_folder_path = \"/content/drive/My Drive/hsv_data/triplet_dataset/validate/anchor\"\n",
        "    # validate_positive_folder_path = \"/content/drive/My Drive/hsv_data/triplet_dataset/validate/positive\"\n",
        "    # validate_negative_folder_path = \"/content/drive/My Drive/hsv_data/triplet_dataset/validate/negative\"\n",
        "\n",
        "    test_anchor_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/test/anchor\"\n",
        "    test_positive_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/test/positive\"\n",
        "    test_negative_folder_path = \"/content/drive/My Drive/datasets_713/triplet_dataset/test/negative\"\n",
        "\n",
        "    image_size = (128, 128)\n",
        "    batch_size = 16\n",
        "    num_epochs = 10\n",
        "    desired_embedding_dim = 128\n",
        "    num_heads = 4\n",
        "    num_layers = 4\n",
        "\n",
        "    # preprocess data\n",
        "    train_anchor_dataloader = preprocess_data(train_anchor_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "    train_positive_dataloader = preprocess_data(train_positive_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "    train_negative_dataloader = preprocess_data(train_negative_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "    # validate_anchor_dataloader = preprocess_data(validate_anchor_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "    # validate_positive_dataloader = preprocess_data(validate_positive_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "    # validate_negative_dataloader = preprocess_data(validate_negative_folder_path, image_size=image_size, batch_size=batch_size)\n",
        "    #\n",
        "    test_anchor_dataloader = preprocess_data(test_anchor_folder_path, image_size=image_size, test=True)\n",
        "    test_positive_dataloader = preprocess_data(test_positive_folder_path, image_size=image_size, test=True)\n",
        "    test_negative_dataloader = preprocess_data(test_negative_folder_path, image_size=image_size, test=True)\n",
        "    test_dataloader = zip(test_anchor_dataloader, test_positive_dataloader, test_negative_dataloader)\n",
        "    # print(test_anchor_dataloader[0])\n",
        "\n",
        "    num_batches = len(train_anchor_dataloader)\n",
        "    print(f\"Number of batches in signature_dataloader: {num_batches}\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'Selected Device: {device}')\n",
        "    siamese_net = SiameseNetwork(embedding_dim=desired_embedding_dim, batch_size=batch_size, num_heads=num_heads,\n",
        "                                 num_layers=num_layers).to(device)   # Use the SiameseNetwork with Transformer\n",
        "\n",
        "    # Train the Siamese network\n",
        "    train_siamese_network(siamese_net, train_anchor_dataloader, train_positive_dataloader, train_negative_dataloader,\n",
        "                            num_epochs)\n",
        "\n",
        "    # Validate the Siamese network\n",
        "\n",
        "    # Test the Siamese network\n",
        "    test_siamese_network(siamese_net, test_dataloader)\n",
        "\n",
        "    # SHAP\n",
        "    # sx.explain_shap_2(siamese_net, train_anchor_dataloader, train_positive_dataloader, train_negative_dataloader)  # Assuming siamese_net is your trained model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfZUnPCXlwaq",
        "outputId": "fcf4b269-8467-4ee2-de1c-1dd9999b1cf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Device: cuda\n",
            "Number of batches in signature_dataloader: 75\n",
            "Selected Device: cuda\n",
            "Epoch 1/10, Loss: 0.0487\n",
            "Epoch 2/10, Loss: 0.0000\n",
            "Epoch 3/10, Loss: 0.0000\n",
            "Epoch 4/10, Loss: 0.0000\n",
            "Epoch 5/10, Loss: 0.0000\n",
            "Epoch 6/10, Loss: 0.0000\n",
            "Epoch 7/10, Loss: 0.0000\n",
            "Epoch 8/10, Loss: 0.0000\n",
            "Epoch 9/10, Loss: 0.0000\n",
            "Epoch 10/10, Loss: 0.0000\n",
            "Total training time: 260.59 seconds\n",
            "Total Correctly Predicted: 78\n",
            "Total Incorrectly Predicted: 22\n",
            "Precision: 1.00\n",
            "Recall: 0.53\n",
            "F1-score: 0.69\n",
            "Accuracy: 78.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gxw6iXXMf9xA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}